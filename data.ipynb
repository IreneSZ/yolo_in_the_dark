{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training and testing\n",
    "\n",
    "class TrainImgLabels(Dataset):\n",
    "    def __init__(self, img_file, batch_size=16, augment=False, class_weights=False):\n",
    "        with open(img_file, \"r\") as fin:\n",
    "            self.img_paths = list(fin.read().splitlines())\n",
    "        n = len(self.img_paths)\n",
    "        batch_idx = np.floor(np.arange(n) / batch_size).astype(np.int)\n",
    "        num_batch = batch_idx[-1] + 1\n",
    "        \n",
    "        self.n = n\n",
    "        self.batch = batch_idx\n",
    "        self.augment = augment\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "        self.label_files = [x.replace('image', 'bbox').               #################what is this for#######\n",
    "                        replace('.jpeg', '.txt').\n",
    "                        replace('.jpg', '.txt').\n",
    "                        replace('.bmp', '.txt').\n",
    "                        replace('.png', '.txt') for x in self.img_paths] \n",
    "        \n",
    "        # preload labels\n",
    "        self.imgs = [None] * n\n",
    "        self.labels = [np.zeros((0, 5))] * n\n",
    "        iter = tqdm(self.label_files, desc='Reading labels')\n",
    "        for i, file in enumerate(iter):\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    l = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32)\n",
    "                    if l.shape[0]:\n",
    "                        assert l.shape[1] == 5, '> 5 label columns: %s' % file\n",
    "                        assert (l >= 0).all(), 'negative labels: %s' % file\n",
    "                        assert (l[:, 1:] <= 1).all(), 'non-normalized or out of bounds coordinate labels: %s' % file\n",
    "                        self.labels[i] = l\n",
    "            except FileNotFoundError:\n",
    "                pass  # print('Warning: missing labels for %s' % self.img_files[i])  # missing label file\n",
    "        assert len(np.concatenate(self.labels, 0)) > 0, 'No labels found. Incorrect label paths provided.'\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.class_weights:  #####################################CLASS WEIGHT###################\n",
    "            index = self.indices[index] \n",
    "        \n",
    "        # images\n",
    "        img_path = self.img_paths[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1).astype(np.float32) # BGR to RGB\n",
    "        ##########################WHY NOT MIN MAX NORMALIZATION###########################\n",
    "        img = img / 255.0 \n",
    "        #############################################################################\n",
    "        assert img is not None, \"Image not found\" + img_path\n",
    "        \n",
    "        # load labels\n",
    "        label_path = self.label_files[index]\n",
    "        labels = []\n",
    "#         if os.path.isfile(label_path):\n",
    "#             x = self.labels[index]\n",
    "        nL = len(labels)\n",
    "            \n",
    "        \n",
    "        return torch.from_numpy(img), label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Reading labels:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Reading labels: 100%|██████████| 5/5 [00:00<00:00, 4385.51it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "tmp = TrainImgLabels('./data/img.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 360, 640])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image(Dataset):\n",
    "    def __init__(self, img_txt):\n",
    "        #self.files = sorted(glob.glob(\"%s/*.*\" % folder_path))\n",
    "        with open(img_txt, \"r\") as fin:\n",
    "            self.img_paths = list(fin.read().splitlines())\n",
    "        #self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index % len(self.img_paths)]\n",
    "        # Extract image as PyTorch tensor\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1).astype(np.float32) # BGR to RGB\n",
    "        ############################### /255 for normalization for now################\n",
    "        img /= 255\n",
    "        #############################################################################\n",
    "#         # Pad to square resolution\n",
    "#         img, _ = pad_to_square(img, 0)\n",
    "#         # Resize\n",
    "#         img = resize(img, self.img_size)\n",
    "\n",
    "        return img_path, img\n",
    "\n",
    "class Label(Dataset):\n",
    "    def __init__(self, label_txt):\n",
    "        with open(label_txt, \"r\") as fin:\n",
    "            self.label_paths = list(fin.read().splitlines())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label_path = self.label_paths[index % len(self.label_paths)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Image('./data/img.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for web cam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
